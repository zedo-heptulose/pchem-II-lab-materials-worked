{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e96f4f11-c349-4504-ad16-d01a4c4c2e21",
   "metadata": {},
   "source": [
    "# LIBRARIES\n",
    "* Execute this cell before going any further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3a09f7f-7195-4372-823d-b490ada84711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906be93d-c21d-4db1-af32-8970d43ea148",
   "metadata": {},
   "source": [
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cde6d6d-5e7a-48c2-9fc9-855d24d8cf5b",
   "metadata": {},
   "source": [
    "# Warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d988a-5e6f-4dda-b269-781e23204ad8",
   "metadata": {},
   "source": [
    "## DataFrames and Tabular Data\n",
    "You’ve likely worked with tabular data before, especially in Excel. In Python, we use the `pandas` library (imported as `pd`) to handle this type of data efficiently. The core component of pandas is the `pd.DataFrame` object, which functions much like a spreadsheet. Proficiency in `pandas` is an evergreen skill—it can make data processing tens or even hundreds of times faster compared to manual work in Excel.\n",
    "\n",
    "In this warmup, we'll explore the basics of the `pd.DataFrame` using a simple dataset. This will prepare you for the extensive use we'll make of this data structure throughout the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f698fc9c-f7d8-4446-a206-90faf06d1908",
   "metadata": {},
   "source": [
    "### CODE\n",
    "* Create three lists of data (e.g., numbers, names, or categories).\n",
    "* Store these lists in a dictionary, using meaningful labels as keys.\n",
    "* Use the pd.DataFrame constructor to create a DataFrame from the dictionary.\n",
    "* Display the DataFrame by making it the last line of a code cell. What does it look like?\n",
    "* Multiply a column by 5, store the result in a new column on the DataFrame, and display the updated DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8acf800c-0473-4c45-b53b-1a298f10eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "students      = ['Bob','Alice','Giancarlo']\n",
    "test_scores   = [95,85,75]\n",
    "gpa           = [3.0,2.0,5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c923c00-4bdf-45e8-95e0-4bc6e0aee8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = {\n",
    "    # Just like we define dictionaries with angle brackets [],\n",
    "    # we define dictionaries with braces {}.\n",
    "    # we define key-value pairs with the key and value paired by a colon\n",
    "    # and successive key-value pairs separated by commas, like follows:\n",
    "    # 'my_key' : some_list,\n",
    "    # 'another_key' : another_list,\n",
    "    # (remember these are just placeholder names!)\n",
    "    #define your own dictionary, using the three lists above.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b7eb4-a975-4ae4-95c0-125d7b081f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataframe = pd.DataFrame(# call pd.DataFrame() as a function.\n",
    "#use the dict my_data as an argument. \n",
    "#end this block with the variable my_dataframe alone on a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c22435-2b4f-45fd-86a5-cb68fff033c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can access columns using angle brackets [],\n",
    "#just like we can access data in a dictionary by key.\n",
    "#we can make new columns by using the angle brackets []\n",
    "#specifying a column that doesn't exist, like as follows:\n",
    "#my_dataframe['some_column'] = my_dataframe['old_column'] + 7 \n",
    "#(this would add 7 to every element in the column with title 'old_column')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7505aa-5c1d-4db5-a495-3238122e5b9f",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dceafcf-4c98-4cc0-ad95-d51ce4b01700",
   "metadata": {},
   "source": [
    "# The Photoelectric Effect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9932c1ec-d4af-42dc-94aa-70913369d751",
   "metadata": {},
   "source": [
    "## PART 1 - Defining our Routine\n",
    "If we would embark on a data processing journey, it is a reasonable first step to get a map for ourselves. It is very hard, after all, to write code if you do not know what you are doing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4c07b1-5771-4c34-b766-b5f16d8777bd",
   "metadata": {},
   "source": [
    "### SHORT RESPONSE QUESTIONS\n",
    "1. What is the terminal information we are trying to find?\n",
    "2. What do we need to know to calculate this data?\n",
    "3. What data do we have from our experiments?\n",
    "4. How can we derive our intermediate data from our experimental data, and our terminal data from our intermediate data? (Include equations, if necessary)\n",
    "### ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c8cf70-3cf2-4d7d-b777-6707f3b0c264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a64faa1-7133-45f5-8e65-72dac133673e",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a98ec1-5f44-471d-aec5-720f087cf042",
   "metadata": {},
   "source": [
    "## PART 2 - Loading and Plotting Data\n",
    "We want to process our data using `pandas`. The first thing we must do is load it into memory as a `pd.DataFrame` object. We will not use the constructor as before. Rather, we will use `pd.read_csv()`. Once we have our data, it is rather difficult to tell what is going on by staring at columns of numbers; in fact, Jupyter will not usually display more than a few dozen values before it truncates the `DataFrame`. We can use `plt.plot()` to visualize the relationships between columns in our `DataFrame.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8d617b-ba87-4af3-9a6c-5fa24ae07cfc",
   "metadata": {},
   "source": [
    "### GIVEN FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c8206f8-d599-488a-ae8b-2e3baacb3876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(dataframe,x_column,y_column,title,trendline_coeffs=None,output_file=None):\n",
    "    x = dataframe[x_column]\n",
    "    y = dataframe[y_column]\n",
    "\n",
    "    plt.scatter(x,y, label = 'Data Points', color='blue')\n",
    "\n",
    "    plt.xlabel(x_column)\n",
    "    plt.ylabel(y_column)\n",
    "    plt.title(title)\n",
    "\n",
    "    if trendline_coeffs is not None:\n",
    "        poly_coeff = trendline_coeffs\n",
    "        poly_degree = len(trendline_coeffs) -1\n",
    "        poly = np.poly1d(poly_coeff)\n",
    "        x_fit = np.linspace(x.min(),x.max(), 500)\n",
    "        y_fit = poly(x_fit)\n",
    "    \n",
    "        plt.plot(x_fit, y_fit, label=f'Polynomial Fit (Degree {poly_degree})',color='red')\n",
    "        \n",
    "        equation_text = \"$y = \" + \" + \".join([f\"{coef:.3e}x^{poly_degree - i}\" if i != poly_degree else f\"{round(coef, 3)}\"\n",
    "                                              for i, coef in enumerate(poly_coeff)]) + \"$\"\n",
    "        plt.text(0.2,0.8, equation_text, transform=plt.gca().transAxes, fontsize=8,\n",
    "                 verticalalignment='bottom', horizontalalignment='left')\n",
    "        plt.legend()\n",
    "\n",
    "    if output_file:\n",
    "        plt.savefig(output_file,format='png',dpi=300, bbox_inches='tight')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c000d91-9436-48bc-bd9b-a6037a3c9256",
   "metadata": {},
   "source": [
    "### CODE\n",
    "* use `pd.read_csv(filename)` to open your data.\n",
    "* Show the contents.\n",
    "* Use `plt.plot(x,y)` to display the spectrum contained in the data.\n",
    "* Apply some basic formatting to your plot using the provided functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7390aa98-1eb6-40da-aad8-0cf2eb0c1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e33338-25be-475c-9d0f-337067673356",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(#use data['some_key'] for the x and y arguments.)\n",
    "plt.title()\n",
    "plt.ylabel()\n",
    "plt.xlabel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad55e7-dc1f-46db-9194-43e0cd509b78",
   "metadata": {},
   "source": [
    "### SHORT RESPONSE QUESTIONS\n",
    "1. What are the names of each of the columns in `data`? How many rows are there?\n",
    "2. Describe the qualitative trends in our spectrum based on the plot you made.\n",
    "### ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3a748-07e4-47e2-9b40-3fe0b41bb1d8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c32ef20d-a05e-43d6-bce4-ff19670ba73e",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8fac49-bcd4-4a07-8ca4-17387ac5e219",
   "metadata": {},
   "source": [
    "## PART 3 - Deriving Values\n",
    "There are two major ways we can process our data now. \n",
    "1. We can do operations on columns to obtain new columns (such as converting wavelengths to frequencies using a formula).\n",
    "2. We can do operations on columns to obtain one or more scalar values (such as the linear coefficients or x-intercept of two columns $x$ and $y$).\n",
    "3. We can filter our DataFrame using some condition to include only values in a valid range (such as getting rid of all zero values).\n",
    "\n",
    "Our next step would be to calculate the following:\n",
    "1. The energy of the wavelength of light.\n",
    "2. The cutoff voltage.\n",
    "3. The work function.\n",
    "\n",
    "How can we accomplish this using these three basic operations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d90d14-a99e-4393-95ba-fc0ec472afc3",
   "metadata": {},
   "source": [
    "### GIVEN FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04e083bd-7db0-4a64-be91-b1f193faa658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_data(dataframe,xcol,ycol,y_threshold):\n",
    "    '''\n",
    "    returns a dataframe including only the first value\n",
    "    lower than or equal to y_threshold\n",
    "    '''\n",
    "    for index, y_value in enumerate(dataframe[ycol]):\n",
    "        if y_value <= y_threshold:\n",
    "            #return dataframe only up to and including this value\n",
    "            return dataframe.iloc[0:index + 1]\n",
    "    #nothing was below threshold\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "628c277c-2706-4ca7-9d19-64f0428c6f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_root_and_yint(data,x_column,y_column,poly_degree=2,interval=[0,np.inf]):\n",
    "    x = data[x_column]\n",
    "    y = data[y_column]\n",
    "\n",
    "    poly_coeff = np.polyfit(x,y,poly_degree)\n",
    "\n",
    "    try:\n",
    "        root = min([float(root) for root in np.roots(poly_coeff) if interval[0] < root and root < interval[1]])\n",
    "    except:\n",
    "        root = np.nan\n",
    "    yint = float(poly_coeff[-1])\n",
    "\n",
    "    return root,yint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade08d51-be41-4fa9-a2f7-b1d3b1e0c89c",
   "metadata": {},
   "source": [
    "### CODE\n",
    "* Perform a polynomial fit on your data using np.polyfit(x_data,y_data,degree).   \n",
    "* Using the provided function, plot this fit.  \n",
    "* Also try truncating the zero values out of your data and applying a linear fit. Which method do you expect to give better results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae37d1f-952b-49e0-9675-542cc1895d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93c634a6-2bb9-48ff-b005-036465bd6bca",
   "metadata": {},
   "source": [
    "### TEXT ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cf9bb8-19c8-4d88-b610-8eb794cff3f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf4935b1-378b-45c9-b9ca-fd1c98df8ca9",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<br/><br/>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6aaa1e-85d9-452c-9f28-d6d0aa06cac7",
   "metadata": {},
   "source": [
    "## PART 4 - Automating our Routine\n",
    "We've separately put together functions for all the different intermediate variables we need for one set of data for a given wavelength. We will, however, need to do this for every spectrum for every wavelength. We've said before that Python is excellent for automating repetitive tasks. If you can do something once, you can do it ten thousand times. We will build two functions - one which uses everything we just did to run our whole intermediate variable routine for one spectrum, and another which uses this for all wavelengths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b114d43-40a0-484a-9b84-908f61a6a100",
   "metadata": {},
   "source": [
    "### GIVEN FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "258476ea-cb38-4814-8869-f8bb894fd77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dataframe,xcol,ycol,lambda_nm,poly_degree):\n",
    "    data = truncate_data(dataframe,xcol,ycol,0.01)\n",
    "    data_dict = {}\n",
    "\n",
    "    poly_coeff = np.polyfit(data[xcol],data[ycol],poly_degree)   \n",
    "    root_yint = find_root_and_yint(data,xcol,ycol, poly_degree)\n",
    "    V0 = root_yint[0]\n",
    "    phi = calculate_phi(V0,200)\n",
    "    nu_lambda = calculate_cutoff_nu_lambda(phi)\n",
    "    cutoff_nu_Hz = nu_lambda[0]\n",
    "    cutoff_lambda_nm = nu_lambda[1]\n",
    "\n",
    "    data_dict['Wavelength(nm)'] = lambda_nm\n",
    "    data_dict['Frequency(Hz)'] = float(c) / (float(lambda_nm) * 1e-9)\n",
    "    data_dict['Stopping Potential(V)'] = V0\n",
    "    data_dict['Work Function(J)'] = phi\n",
    "    data_dict['Cut-off Frequency(Hz)'] = cutoff_nu_Hz\n",
    "    data_dict['Cut-off Wavelength(nm)'] = cutoff_lambda_nm\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0530b666-631b-43cb-a7c3-ecb43c0bb487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files():\n",
    "    filenames = os.listdir('./') #'./' is the current directory\n",
    "    csv_files = [file for file in filenames if file.endswith('.csv')]\n",
    "    data = {}\n",
    "    for filename in csv_files:\n",
    "        wavelength_nm = re.search('\\d+',filename).group(0)\n",
    "        data[wavelength_nm] = pd.read_csv(filename)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d359a2f2-b43f-4720-8949-d33be125fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(table_data,poly_degree):\n",
    "    table = pd.DataFrame({'Wavelength(nm)':[],\n",
    "                   'Frequency(Hz)':[],\n",
    "                   'Work Function(J)':[],\n",
    "                   'Stopping Potential(V)':[],\n",
    "                   'Cut-off Frequency(Hz)':[],\n",
    "                   'Cut-off Wavelength(nm)':[]})\n",
    "    for wavelength in table_data:\n",
    "        derived_values = process_data(table_data[wavelength],xcol,ycol,wavelength,poly_degree)\n",
    "        derived_values = {key : [value] for key,value in derived_values.items()}\n",
    "        row = pd.DataFrame(derived_values)\n",
    "        numeric_values = pd.to_numeric(row.values.flatten(), errors='coerce')\n",
    "        if not np.isnan(numeric_values).any():\n",
    "            table = pd.concat([table,row])\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88468c83-3898-4380-85ad-b8d2e5141962",
   "metadata": {},
   "source": [
    "### CODE\n",
    "* Complete the `process_data()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa754c7-1e4c-444f-8900-039adab6bccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d48e131-ec7e-4633-aae8-081c7ca8c112",
   "metadata": {},
   "source": [
    "## TEXT ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff9c3c-e90c-43d2-9621-97b6877497f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af85cd97-52e6-4c32-ad6b-b4eadda51a25",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<br/><br/>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0457a5a0-b160-4f5e-a820-afdc485319bf",
   "metadata": {},
   "source": [
    "## Part 5 - Calculating our Terminal Data\n",
    "Using the data collected from all of our files, perform a linear regression to obtain Planck's constant. Is Planck's constant the slope or the intercept?  \n",
    "Also, compare the value you obtain from Planck's constant to the literature value and calculate a percent error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11fab3-7fee-4bca-8993-ddb35756e404",
   "metadata": {},
   "source": [
    "## CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd208e81-a8f5-4a90-b337-600f359d15e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebfdc9b5-0fd9-4a29-8ee0-bc833d20a18a",
   "metadata": {},
   "source": [
    "## TEXT ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9e1eed-69f6-46d3-a8e9-81e2d77f0949",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85a04c6c-5617-4142-a796-71b0644fa0d5",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a16167-66cc-427a-bb04-961f9b3a2ca5",
   "metadata": {},
   "source": [
    "# REFLECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c314fe-c1a9-4779-bacb-6c9ae9e70224",
   "metadata": {},
   "source": [
    "This same experiment was taught in prior years, using Excel instead of Python. Which method would you prefer to use, and why?  \n",
    "For which situations would it be better to use a tool like Excel, and for which situations would it be better to use Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e022ab6f-dd21-4e72-8d25-b2cc9fa5520a",
   "metadata": {},
   "source": [
    "## TEXT ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14897a7-6cd2-419f-bd45-08e1be384b6b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6adf375-2aae-453f-b6e2-f07aa10f7a51",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<br/><br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
